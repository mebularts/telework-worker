name: High Frequency Scraper

on:
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      # CACHE ADIMI: seen_urls.json dosyasını saklamak için
      - name: Cache Seen URLs
        uses: actions/cache@v3
        with:
          path: seen_urls.json
          key: seen-urls-${{ github.run_id }}
          restore-keys: |
            seen-urls-
          
      - name: Install dependencies
        run: |
          npm install
          npx playwright install chromium
          
      - name: Run Scraper
        run: |
          node index.js
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
          SCRAPER_TOKEN: ${{ secrets.SCRAPER_TOKEN }}
          SCRAPER_COOKIES_JSON: ${{ secrets.SCRAPER_COOKIES_JSON }}
          SCRAPE_DO_TOKEN: ${{ secrets.SCRAPE_DO_TOKEN }}
          CAPTCHA_TOKEN: ${{ secrets.CAPTCHA_TOKEN }}
          SCRAPER_PROXY: ${{ secrets.SCRAPER_PROXY }}
          UPWORK_ENABLED: 1
          UPWORK_USE_SCRAPE_DO: 0
          SCRAPER_DETAIL_CONCURRENCY: 3
          SCRAPER_DETAIL_DELAY_MS: 200

      - name: Upload Debug Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-debug
          path: |
            *.png
            *.html
            seen_urls.json
          retention-days: 1
